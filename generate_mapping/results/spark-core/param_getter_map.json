{
  "org.apache.spark.scheduler.DAGSchedulerSuite @ run trivial job w/ dependency": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ [SPARK-3353] parent stage should have lower stage id": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.reducer.maxReqsInFlight",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.excludeOnFailure.enabled",
    "spark.reducer.maxBlocksInFlightPerAddress",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.log.callerContext",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.shuffle.file.buffer",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.speculation.efficiency.longRunTaskFactor",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.speculation.quantile",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.default.parallelism",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.speculation.task.duration.threshold",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.detectCorrupt",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.speculation.efficiency.processRateMultiplier",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.shuffle.unsafe.file.output.buffer",
    "spark.locality.wait.node",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.shuffle.checksum.algorithm",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.shuffle.detectCorrupt.useExtraMemory",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.shuffle.checksum.enabled",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.reducer.maxSizeInFlight",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.speculation.multiplier",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ [SPARK-13902] Ensure no duplicate stages are created": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ All shuffle files on the storage endpoint should be cleaned up when it is lost": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.shuffle.service.fetch.rdd.enabled",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.shuffle.service.removeShuffle",
    "spark.shuffle.registration.timeout",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-32003: All shuffle files for executor should be cleaned up on fetch failure": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.shuffle.service.fetch.rdd.enabled",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.shuffle.service.removeShuffle",
    "spark.shuffle.registration.timeout",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ zero split job": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ run trivial job": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ cache location preferences w/ dependency": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ regression test for getCacheLocs": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ getMissingParentStages should consider all ancestor RDDs' cache statuses": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ avoid exponential blowup when getting preferred locs list": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ unserializable task": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ trivial job failure": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ trivial job cancellation": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ job cancellation no-kill backend": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ run trivial shuffle": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ run trivial shuffle with fetch failure": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ shuffle files not lost when executor process lost with shuffle service": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.shuffle.service.fetch.rdd.enabled",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.shuffle.service.removeShuffle",
    "spark.shuffle.registration.timeout",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ shuffle files lost when worker lost with shuffle service": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.shuffle.service.fetch.rdd.enabled",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.shuffle.service.removeShuffle",
    "spark.shuffle.registration.timeout",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ shuffle files lost when worker lost without shuffle service": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ shuffle files not lost when executor failure with shuffle service": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.shuffle.service.fetch.rdd.enabled",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.shuffle.service.removeShuffle",
    "spark.shuffle.registration.timeout",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ shuffle files lost when executor failure without shuffle service": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-28967 properties must be cloned before posting to listener bus for 0 partition": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ Single stage fetch failure should not abort the stage.": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ Multiple consecutive stage fetch failures should lead to job being aborted.": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ Failures in different stages should not trigger an overall abort": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ Non-consecutive stage failures don't trigger abort": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ trivial shuffle with multiple fetch failures": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ Retry all the tasks on a resubmitted attempt of a barrier stage caused by FetchFailure": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ Retry all the tasks on a resubmitted attempt of a barrier stage caused by TaskKilled": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ Fail the job if a barrier ResultTask failed": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ late fetch failures don't cause multiple concurrent attempts for the same map stage": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ extremely late fetch failures don't cause multiple concurrent attempts for the same stage": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ task events always posted in speculation / when stage is killed": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ ignore late map task completions": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ run shuffle with map stage failure": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ shuffle fetch failure in a reused shuffle dependency": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ don't submit stage until its dependencies map outputs are registered (SPARK-5259)": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ register map outputs correctly after ExecutorLost and task Resubmitted": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ failure of stage used by two jobs": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ run trivial shuffle with out-of-band executor failure and retry": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ recursive shuffle failures": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ cached post-shuffle": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ misbehaved accumulator should not crash DAGScheduler and SparkContext": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.excludeOnFailure.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.log.callerContext",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.speculation.efficiency.longRunTaskFactor",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.speculation.quantile",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.speculation.task.duration.threshold",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.speculation.efficiency.processRateMultiplier",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.speculation.multiplier",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ misbehaved accumulator should not impact other accumulators": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.excludeOnFailure.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.log.callerContext",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.speculation.efficiency.longRunTaskFactor",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.speculation.quantile",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.speculation.task.duration.threshold",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.speculation.efficiency.processRateMultiplier",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.speculation.multiplier",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ misbehaved resultHandler should not crash DAGScheduler and SparkContext": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.excludeOnFailure.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.log.callerContext",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.speculation.efficiency.longRunTaskFactor",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.speculation.quantile",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.speculation.task.duration.threshold",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.speculation.efficiency.processRateMultiplier",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.speculation.multiplier",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ invalid spark.job.interruptOnCancel should not crash DAGScheduler": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.excludeOnFailure.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.log.callerContext",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.speculation.efficiency.longRunTaskFactor",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.speculation.quantile",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.speculation.task.duration.threshold",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.speculation.efficiency.processRateMultiplier",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.speculation.multiplier",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ getPartitions exceptions should not crash DAGScheduler and SparkContext (SPARK-8606)": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.excludeOnFailure.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.log.callerContext",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.speculation.efficiency.longRunTaskFactor",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.speculation.quantile",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.speculation.task.duration.threshold",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.speculation.efficiency.processRateMultiplier",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.speculation.multiplier",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ getPreferredLocations errors should not crash DAGScheduler and SparkContext (SPARK-8606)": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.excludeOnFailure.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.log.callerContext",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.speculation.efficiency.longRunTaskFactor",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.speculation.quantile",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.speculation.task.duration.threshold",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.speculation.efficiency.processRateMultiplier",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.speculation.multiplier",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ accumulator not calculated for resubmitted result stage": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ accumulator not calculated for resubmitted task in result stage": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ accumulators are updated on exception failures and task killed": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ reduce tasks should be placed locally with map output": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ reduce task locality preferences should only include machines with largest map outputs": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ stages with both narrow and shuffle dependencies use narrow ones for locality": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ Spark exceptions should include call site in stack trace": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.excludeOnFailure.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.log.callerContext",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.speculation.efficiency.longRunTaskFactor",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.speculation.quantile",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.speculation.task.duration.threshold",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.speculation.efficiency.processRateMultiplier",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.speculation.multiplier",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ catch errors in event loop": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ simple map stage submission": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ map stage submission with reduce stage also depending on the data": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ map stage submission with fetch failure": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ map stage submission with multiple shared stages and failures": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ Trigger mapstage's job listener in submitMissingTasks": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ map stage submission with executor failure late map task completions": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ getShuffleDependenciesAndResourceProfiles correctly returns only direct shuffle parents": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ task end event should have updated accumulators (SPARK-20342)": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.excludeOnFailure.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.log.callerContext",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.speculation.efficiency.longRunTaskFactor",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.speculation.quantile",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.speculation.task.duration.threshold",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.speculation.efficiency.processRateMultiplier",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.speculation.multiplier",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ Barrier task failures from the same stage attempt don't trigger multiple stage retries": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ Barrier task failures from a previous stage attempt don't trigger stage retry": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-25341: abort stage while using old fetch protocol": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-25341: retry all the succeeding stages when the map stage is indeterminate": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-25341: continuous indeterminate stage roll back": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-29042: Sampled RDD with unordered input should be indeterminate": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-23207: cannot rollback a result stage": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-23207: local checkpoint fail to rollback (checkpointed before)": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.excludeOnFailure.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.log.callerContext",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.speculation.efficiency.longRunTaskFactor",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.speculation.quantile",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.speculation.task.duration.threshold",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.speculation.efficiency.processRateMultiplier",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.speculation.multiplier",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-23207: local checkpoint fail to rollback (checkpointing now)": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-23207: reliable checkpoint can avoid rollback (checkpointed before)": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.excludeOnFailure.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.log.callerContext",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.speculation.efficiency.longRunTaskFactor",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.speculation.quantile",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.speculation.task.duration.threshold",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.speculation.efficiency.processRateMultiplier",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.speculation.multiplier",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.cleaner.referenceTracking.cleanCheckpoints",
    "spark.checkpoint.compress",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-23207: reliable checkpoint fail to rollback (checkpointing now)": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-27164: RDD.countApprox on empty RDDs schedules jobs which never complete": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ Completions in zombie tasksets update status of non-zombie taskset": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ test default resource profile": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.default.parallelism",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ test 2 resource profiles errors by default": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.default.parallelism",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ test 2 resource profile with merge conflict config true": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.default.parallelism",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ test multiple resource profiles created from merging use same rp": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.default.parallelism",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ getShuffleDependenciesAndResourceProfiles returns deps and profiles correctly": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-32920: shuffle merge finalization": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.shuffle.service.fetch.rdd.enabled",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.push.numPushThreads",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.shuffle.service.removeShuffle",
    "spark.shuffle.registration.timeout",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-32920: merger locations not empty": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.shuffle.service.fetch.rdd.enabled",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.push.numPushThreads",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.shuffle.service.removeShuffle",
    "spark.shuffle.registration.timeout",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-32920: merger locations reuse from shuffle dependency": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.shuffle.service.fetch.rdd.enabled",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.push.numPushThreads",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.shuffle.service.removeShuffle",
    "spark.shuffle.registration.timeout",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-32920: Disable shuffle merge due to not enough mergers available": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.shuffle.service.fetch.rdd.enabled",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.push.numPushThreads",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.shuffle.service.removeShuffle",
    "spark.shuffle.registration.timeout",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.shuffle.push.mergersMinStaticThreshold",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-32920: Ensure child stage should not start before all the parent stages are completed with shuffle merge finalized for all the parent stages": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.shuffle.service.fetch.rdd.enabled",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.push.numPushThreads",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.shuffle.service.removeShuffle",
    "spark.shuffle.registration.timeout",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-32920: Reused ShuffleDependency with Shuffle Merge disabled for the corresponding ShuffleDependency should not cause DAGScheduler to hang": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.shuffle.service.fetch.rdd.enabled",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.push.numPushThreads",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.shuffle.service.removeShuffle",
    "spark.shuffle.registration.timeout",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.shuffle.push.mergersMinStaticThreshold",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-32920: Reused ShuffleDependency with Shuffle Merge disabled for the corresponding ShuffleDependency with shuffle data loss should recompute missing partitions": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.shuffle.service.fetch.rdd.enabled",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.push.numPushThreads",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.shuffle.service.removeShuffle",
    "spark.shuffle.registration.timeout",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.shuffle.push.mergersMinStaticThreshold",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-32920: Empty RDD should not be computed": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.reducer.maxReqsInFlight",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.excludeOnFailure.enabled",
    "spark.reducer.maxBlocksInFlightPerAddress",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.log.callerContext",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.shuffle.file.buffer",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.speculation.efficiency.longRunTaskFactor",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.shuffle.service.fetch.rdd.enabled",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.speculation.quantile",
    "spark.shuffle.push.numPushThreads",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.speculation.task.duration.threshold",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.detectCorrupt",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.speculation.efficiency.processRateMultiplier",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.shuffle.checksum.algorithm",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.shuffle.detectCorrupt.useExtraMemory",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.shuffle.checksum.enabled",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.shuffle.service.removeShuffle",
    "spark.shuffle.registration.timeout",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.reducer.maxSizeInFlight",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.speculation.multiplier",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-32920: Cancelled stage should be marked finalized after the shuffle merge is finalized": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.shuffle.service.fetch.rdd.enabled",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.push.numPushThreads",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.shuffle.service.removeShuffle",
    "spark.shuffle.registration.timeout",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-32920: SPARK-35549: Merge results should not get registered after shuffle merge finalization": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.shuffle.service.fetch.rdd.enabled",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.push.numPushThreads",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.shuffle.service.removeShuffle",
    "spark.shuffle.registration.timeout",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-32920: Disable push based shuffle in the case of a barrier stage": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.shuffle.service.fetch.rdd.enabled",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.push.numPushThreads",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.shuffle.service.removeShuffle",
    "spark.shuffle.registration.timeout",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-32920: metadata fetch failure should not unregister map status": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.shuffle.service.fetch.rdd.enabled",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.push.numPushThreads",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.shuffle.service.removeShuffle",
    "spark.shuffle.registration.timeout",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.shuffle.push.mergersMinStaticThreshold",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-32923: handle stage failure for indeterminate map stage with push-based shuffle": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.shuffle.service.fetch.rdd.enabled",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.push.numPushThreads",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.shuffle.service.removeShuffle",
    "spark.shuffle.registration.timeout",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-33701: check adaptive shuffle merge finalization triggered after stage completion": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.shuffle.service.fetch.rdd.enabled",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.push.numPushThreads",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.shuffle.service.removeShuffle",
    "spark.shuffle.registration.timeout",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-33701: check adaptive shuffle merge finalization triggered after minimum threshold push complete": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.shuffle.service.fetch.rdd.enabled",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.push.numPushThreads",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.shuffle.service.removeShuffle",
    "spark.shuffle.registration.timeout",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-33701: check adaptive shuffle merge finalization behavior with stage cancellation for determinate and indeterminate stages during spark.shuffle.push.finalize.timeout wait": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.shuffle.service.fetch.rdd.enabled",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.push.numPushThreads",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.shuffle.service.removeShuffle",
    "spark.shuffle.registration.timeout",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-33701: check adaptive shuffle merge finalization with minimum pushes complete after the stage completion replacing the finalize task with delay = 0": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.shuffle.service.fetch.rdd.enabled",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.push.numPushThreads",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.shuffle.service.removeShuffle",
    "spark.shuffle.registration.timeout",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-34826: Adaptively fetch shuffle mergers": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.shuffle.service.fetch.rdd.enabled",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.push.numPushThreads",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.shuffle.service.removeShuffle",
    "spark.shuffle.registration.timeout",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.shuffle.push.mergersMinStaticThreshold",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-34826: Adaptively fetch shuffle mergers with stage retry": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.shuffle.service.fetch.rdd.enabled",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.push.numPushThreads",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.shuffle.service.removeShuffle",
    "spark.shuffle.registration.timeout",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.shuffle.push.mergersMinStaticThreshold",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-34826: Adaptively fetch shuffle mergers with stage retry for indeterminate stage": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.shuffle.service.fetch.rdd.enabled",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.push.numPushThreads",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.shuffle.service.removeShuffle",
    "spark.shuffle.registration.timeout",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.shuffle.push.mergersMinStaticThreshold",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-38987: corrupted merged shuffle block FetchFailure should unregister merge results": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.shuffle.service.fetch.rdd.enabled",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.push.numPushThreads",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.shuffle.service.removeShuffle",
    "spark.shuffle.registration.timeout",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-38987: All shuffle outputs for a shuffle push merger executor should be cleaned up on a fetch failure whenspark.files.fetchFailure.unRegisterOutputOnHost is true": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.shuffle.service.fetch.rdd.enabled",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.push.numPushThreads",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.io.compression.codec",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.broadcast.checksum",
    "spark.broadcast.blockSize",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.shuffle.service.removeShuffle",
    "spark.shuffle.registration.timeout",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.shuffle.push.mergersMinStaticThreshold",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.io.compression.lz4.blockSize",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-40096: Send finalize events even if shuffle merger blocks indefinitely with registerMergeResults is true": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.shuffle.service.fetch.rdd.enabled",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.push.numPushThreads",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.shuffle.service.removeShuffle",
    "spark.shuffle.registration.timeout",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ],
  "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-40096: Send finalize events even if shuffle merger blocks indefinitely with registerMergeResults is false": [
    "spark.memory.offHeap.enabled",
    "spark.ui.retainedDeadExecutors",
    "spark.shuffle.mapOutput.minSizeForBroadcast",
    "spark.shuffle.compress",
    "spark.storage.localDiskByExecutors.cacheSize",
    "spark.shuffle.push.maxRetainedMergerLocations",
    "spark.ui.retainedJobs",
    "spark.eventLog.enabled",
    "spark.shuffle.io.numConnectionsPerPeer",
    "spark.rpc.lookupTimeout",
    "spark.shuffle.readHostLocalDisk",
    "spark.ui.liveUpdate.period",
    "spark.driver.port",
    "spark.kryo.registrator",
    "spark.shuffle.push.enabled",
    "spark.executor.memoryOverhead",
    "spark.shuffle.push.merge.finalizeThreads",
    "spark.speculation",
    "spark.cleaner.referenceTracking",
    "spark.appStatusStore.diskStoreDir",
    "spark.ui.showConsoleProgress",
    "spark.dynamicAllocation.enabled",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.interval",
    "spark.port.maxRetries",
    "spark.kryoserializer.buffer.max",
    "spark.task.cpus",
    "spark.driver.blockManager.port",
    "spark.executor.metrics.fileSystemSchemes",
    "spark.executor.heartbeatInterval",
    "spark.network.timeout",
    "spark.executor.userClassPathFirst",
    "spark.storage.memoryMapThreshold",
    "spark.ui.reverseProxy",
    "spark.shuffle.service.fetch.rdd.enabled",
    "spark.logConf",
    "spark.rpc.message.maxSize",
    "spark.shuffle.push.numPushThreads",
    "spark.shuffle.io.retryWait",
    "spark.memory.storageFraction",
    "spark.shuffle.useOldFetchProtocol",
    "spark.eventLog.compress",
    "spark.cleaner.referenceTracking.blocking",
    "spark.kryo.unsafe",
    "spark.memory.offHeap.size",
    "spark.shuffle.reduceLocality.enabled",
    "spark.driver.host",
    "spark.shuffle.service.enabled",
    "spark.ui.enabled",
    "spark.ui.retainedStages",
    "spark.executor.metrics.pollingInterval",
    "spark.driver.extraJavaOptions",
    "spark.ui.liveUpdate.minFlushPeriod",
    "spark.app.name",
    "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version",
    "spark.scheduler.listenerbus.eventqueue.shared.capacity",
    "spark.ui.retainedTasks",
    "spark.cleaner.referenceTracking.blocking.shuffle",
    "spark.extraListeners",
    "spark.scheduler.listenerbus.eventqueue.capacity",
    "spark.master",
    "spark.shuffle.push.finalize.timeout",
    "spark.shuffle.sort.io.plugin.class",
    "spark.driver.log.persistToDfs.enabled",
    "spark.cleaner.periodicGC.interval",
    "spark.network.maxRemoteBlockSizeFetchToMem",
    "spark.ui.dagGraph.retainedRootRDDs",
    "spark.storage.decommission.fallbackStorage.path",
    "spark.broadcast.compress",
    "spark.shuffle.push.minShuffleSizeToWait",
    "spark.executor.extraClassPath",
    "spark.kryo.registrationRequired",
    "spark.rdd.compress",
    "spark.shuffle.sort.bypassMergeThreshold",
    "spark.network.io.preferDirectBufs",
    "spark.archives",
    "spark.storage.decommission.shuffleBlocks.maxDiskSize",
    "spark.rpc.askTimeout",
    "spark.scheduler.listenerbus.eventqueue.executorManagement.capacity",
    "spark.stage.maxConsecutiveAttempts",
    "spark.files",
    "spark.scheduler.listenerbus.eventqueue.appStatus.capacity",
    "spark.serializer",
    "spark.storage.replication.proactive",
    "spark.speculation.minTaskRuntime",
    "spark.driver.bindAddress",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures",
    "spark.storage.unrollMemoryThreshold",
    "spark.shuffle.spill.compress",
    "spark.jars",
    "spark.executor.cores",
    "spark.shuffle.service.removeShuffle",
    "spark.shuffle.registration.timeout",
    "spark.scheduler.resource.profileMergeConflicts",
    "spark.kryoserializer.buffer",
    "spark.local.dir",
    "spark.executor.extraJavaOptions",
    "spark.shuffle.io.backLog",
    "spark.rpc.io.backLog",
    "spark.executor.memory",
    "spark.memory.fraction",
    "spark.task.reaper.enabled",
    "spark.kryo.referenceTracking",
    "spark.eventLog.longForm.enabled",
    "spark.speculation.interval",
    "spark.driver.maxResultSize",
    "spark.shuffle.push.minCompletedPushRatio",
    "spark.serializer.objectStreamReset",
    "spark.kryo.classesToRegister",
    "spark.executor.pyspark.memory",
    "spark.scheduler.mode"
  ]
}